#!/usr/bin/env python3
"""
ìŒì„± íŒŒì¼ ë…¸ì´ì¦ˆ ì œê±° â†’ Whisper STT â†’ í…ìŠ¤íŠ¸ ì €ì¥ íŒŒì´í”„ë¼ì¸
"""

import os
import sys
import glob
import logging
from pathlib import Path
from datetime import datetime
import torch
import torchaudio
import whisper
import soundfile as sf
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('audio_pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# SpeechBrain importë¥¼ ì¡°ê±´ë¶€ë¡œ ì²˜ë¦¬
try:
    from speechbrain.inference.enhancement import SpectralMaskEnhancement
    from speechbrain.utils.fetching import LocalStrategy
    SPEECHBRAIN_AVAILABLE = True
except ImportError as e:
    logger.warning(f"SpeechBrain ë¡œë”© ì‹¤íŒ¨: {e}")
    SPEECHBRAIN_AVAILABLE = False

class AudioPipeline:
    """ìŒì„± íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, use_gpu=True):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            use_gpu (bool): GPU ì‚¬ìš© ì—¬ë¶€
        """
        self.use_gpu = use_gpu and torch.cuda.is_available()
        self.device = "cuda" if self.use_gpu else "cpu"
        
        # í´ë” ê²½ë¡œ ì„¤ì •
        self.audio_input_dir = Path("audio_input")
        self.audio_out_dir = Path("audio_out") 
        self.audio_output_dir = Path("audio_output")
        self.script_output_dir = Path("script_output")
        
        # í´ë” ìƒì„±
        self._create_directories()
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.denoiser = None
        self.whisper_model = None
        
        logger.info(f"íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        for directory in [self.audio_input_dir, self.audio_out_dir, 
                         self.audio_output_dir, self.script_output_dir]:
            directory.mkdir(exist_ok=True)
            logger.info(f"ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {directory}")
    
    def _load_denoiser(self):
        """ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ë¡œë“œ"""
        if self.denoiser is None:
            if not SPEECHBRAIN_AVAILABLE:
                logger.warning("SpeechBrainì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ëŒ€ì•ˆ ë°©ë²• ì‚¬ìš©")
                self._load_denoiser_alternative()
                return
                
            try:
                logger.info("ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ë¡œë”© ì¤‘...")
                
                # Windows ê¶Œí•œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ LocalStrategy ì‚¬ìš©
                import os
                os.environ['SPEECHBRAIN_CACHE_STRATEGY'] = 'LOCAL'
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ savedir ì„¤ì •
                savedir = os.path.abspath("pretrained_models/metricgan-plus-voicebank")
                
                self.denoiser = SpectralMaskEnhancement.from_hparams(
                    source="speechbrain/metricgan-plus-voicebank",
                    savedir=savedir,
                    run_opts={"device": self.device}
                )
                logger.info("ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                logger.info("ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...")
                try:
                    self._load_denoiser_alternative()
                except Exception as e2:
                    logger.error(f"ëŒ€ì•ˆ ë°©ë²•ë„ ì‹¤íŒ¨: {e2}")
                    raise e
    
    def _load_denoiser_alternative(self):
        """ëŒ€ì•ˆ ë…¸ì´ì¦ˆ ì œê±° ë°©ë²• (ê°„ë‹¨í•œ ìŠ¤í™íŠ¸ëŸ¼ í•„í„°ë§)"""
        logger.info("ëŒ€ì•ˆ ë…¸ì´ì¦ˆ ì œê±° ë°©ë²• ì‚¬ìš© (ê°„ë‹¨í•œ í•„í„°ë§)")
        self.denoiser = "simple_filter"  # í”Œë˜ê·¸ë¡œ ì‚¬ìš©
    
    def _simple_denoise(self, waveform, sample_rate):
        """ê°„ë‹¨í•œ ë…¸ì´ì¦ˆ ì œê±° (ìŠ¤í™íŠ¸ëŸ¼ í•„í„°ë§)"""
        try:
            # ê°„ë‹¨í•œ ê³ ì—­ í†µê³¼ í•„í„° ì ìš©
            from scipy.signal import butter, filtfilt
            
            # 80Hz ì´í•˜ ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±°
            nyquist = sample_rate / 2
            low_cutoff = 80 / nyquist
            b, a = butter(4, low_cutoff, btype='high')
            
            # í•„í„° ì ìš©
            filtered = filtfilt(b, a, waveform.numpy())
            
            # ì •ê·œí™”
            filtered = filtered / np.max(np.abs(filtered)) * 0.8
            
            return torch.from_numpy(filtered).float()
            
        except ImportError:
            logger.warning("scipyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ê°„ë‹¨í•œ ì •ê·œí™”ë§Œ ì ìš©")
            # ê°„ë‹¨í•œ ì •ê·œí™”ë§Œ ì ìš©
            normalized = waveform / torch.max(torch.abs(waveform)) * 0.8
            return normalized
    
    def _load_whisper(self, model_size="base"):
        """Whisper ëª¨ë¸ ë¡œë“œ"""
        if self.whisper_model is None:
            try:
                logger.info(f"Whisper ëª¨ë¸ ({model_size}) ë¡œë”© ì¤‘...")
                self.whisper_model = whisper.load_model(model_size, device=self.device)
                logger.info("Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                raise
    
    def denoise_audio(self, input_file, output_file):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ë…¸ì´ì¦ˆ ì œê±°
        
        Args:
            input_file (str): ì…ë ¥ íŒŒì¼ ê²½ë¡œ
            output_file (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        try:
            logger.info(f"ë…¸ì´ì¦ˆ ì œê±° ì‹œì‘: {input_file}")
            
            # ëª¨ë¸ ë¡œë“œ
            self._load_denoiser()
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            waveform, sample_rate = torchaudio.load(input_file)
            
            # ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ 16kHzë¡œ ë³€í™˜ (SpeechBrain ëª¨ë¸ ìš”êµ¬ì‚¬í•­)
            if sample_rate != 16000:
                resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                waveform = resampler(waveform)
                sample_rate = 16000
            
            # ë…¸ì´ì¦ˆ ì œê±° ìˆ˜í–‰
            if self.denoiser == "simple_filter":
                # ëŒ€ì•ˆ ë°©ë²• ì‚¬ìš©
                logger.info("ê°„ë‹¨í•œ í•„í„°ë§ ë°©ë²•ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°")
                enhanced_waveform = self._simple_denoise(waveform.squeeze(0), sample_rate)
                enhanced_waveform = enhanced_waveform.unsqueeze(0)
            else:
                # SpeechBrain ëª¨ë¸ ì‚¬ìš©
                waveform = waveform.to(self.device)
                enhanced_waveform = self.denoiser.enhance_batch(waveform.unsqueeze(0))
                enhanced_waveform = enhanced_waveform.squeeze(0).cpu()
            
            # ì¶œë ¥ íŒŒì¼ ì €ì¥
            torchaudio.save(output_file, enhanced_waveform, sample_rate)
            
            logger.info(f"ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ: {output_file}")
            
        except Exception as e:
            logger.error(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨ ({input_file}): {e}")
            raise
    
    def transcribe_audio(self, audio_file, output_text_file, srt_file=None):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (STT)
        
        Args:
            audio_file (str): ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            output_text_file (str): ì¶œë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            srt_file (str, optional): SRT ìë§‰ íŒŒì¼ ê²½ë¡œ
        """
        try:
            logger.info(f"STT ì²˜ë¦¬ ì‹œì‘: {audio_file}")
            
            # Whisper ëª¨ë¸ ë¡œë“œ
            self._load_whisper()
            
            # ìŒì„± ì¸ì‹ ìˆ˜í–‰ (ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            result = self.whisper_model.transcribe(
                str(audio_file), 
                language="ko",
                word_timestamps=True,
                verbose=True
            )
            
            # ê²°ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            transcribed_text = result["text"].strip()
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            self._save_transcript_with_timestamps(audio_file, output_text_file, result)
            
            # SRT ìë§‰ íŒŒì¼ ìƒì„± (ìš”ì²­ëœ ê²½ìš°)
            if srt_file:
                self._save_srt_file(srt_file, result)
                logger.info(f"SRT ìë§‰ íŒŒì¼ ìƒì„±: {srt_file}")
            
            logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ: {output_text_file}")
            logger.info(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {transcribed_text[:100]}...")
            
            return transcribed_text
            
        except Exception as e:
            logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ ({audio_file}): {e}")
            raise
    
    def _save_transcript_with_timestamps(self, audio_file, output_text_file, result):
        """íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ì „ì‚¬ ê²°ê³¼ ì €ì¥"""
        with open(output_text_file, 'w', encoding='utf-8') as f:
            # í—¤ë” ì •ë³´
            f.write(f"íŒŒì¼ëª…: {Path(audio_file).name}\n")
            f.write(f"ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì–¸ì–´: {result.get('language', 'unknown')}\n")
            f.write(f"ì´ ê¸¸ì´: {self._format_time(result.get('duration', 0))}\n")
            f.write("=" * 60 + "\n\n")
            
            # ì „ì²´ í…ìŠ¤íŠ¸
            f.write("ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸\n")
            f.write("-" * 30 + "\n")
            f.write(result["text"].strip() + "\n\n")
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
            f.write("â° íƒ€ì„ìŠ¤íƒ¬í”„ë³„ í…ìŠ¤íŠ¸\n")
            f.write("-" * 30 + "\n")
            
            if "segments" in result:
                for i, segment in enumerate(result["segments"], 1):
                    start_time = self._format_time(segment["start"])
                    end_time = self._format_time(segment["end"])
                    text = segment["text"].strip()
                    
                    f.write(f"[{start_time} â†’ {end_time}] {text}\n")
                
                # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ (ê°€ëŠ¥í•œ ê²½ìš°)
                f.write("\nğŸ”¤ ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„\n")
                f.write("-" * 30 + "\n")
                
                for segment in result["segments"]:
                    if "words" in segment:
                        for word_info in segment["words"]:
                            start_time = self._format_time(word_info["start"])
                            end_time = self._format_time(word_info["end"])
                            word = word_info["word"].strip()
                            confidence = word_info.get("probability", 0)
                            
                            f.write(f"[{start_time}-{end_time}] {word} (ì‹ ë¢°ë„: {confidence:.2f})\n")
            else:
                f.write("íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")
    
    def _format_time(self, seconds):
        """ì´ˆë¥¼ MM:SS.mmm í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if seconds is None:
            return "00:00.000"
        
        minutes = int(seconds // 60)
        seconds = seconds % 60
        return f"{minutes:02d}:{seconds:06.3f}"
    
    def _save_srt_file(self, srt_file, result):
        """SRT ìë§‰ íŒŒì¼ ìƒì„±"""
        with open(srt_file, 'w', encoding='utf-8') as f:
            if "segments" in result:
                for i, segment in enumerate(result["segments"], 1):
                    start_time = self._format_srt_time(segment["start"])
                    end_time = self._format_srt_time(segment["end"])
                    text = segment["text"].strip()
                    
                    f.write(f"{i}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{text}\n\n")
            else:
                # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ìë§‰ìœ¼ë¡œ
                duration = result.get("duration", 60)  # ê¸°ë³¸ 60ì´ˆ
                start_time = self._format_srt_time(0)
                end_time = self._format_srt_time(duration)
                text = result["text"].strip()
                
                f.write("1\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{text}\n\n")
    
    def _format_srt_time(self, seconds):
        """ì´ˆë¥¼ SRT í˜•ì‹ (HH:MM:SS,mmm)ìœ¼ë¡œ ë³€í™˜"""
        if seconds is None:
            return "00:00:00,000"
        
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = seconds % 60
        milliseconds = int((secs % 1) * 1000)
        secs = int(secs)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
    
    def process_single_file(self, input_file):
        """
        ë‹¨ì¼ íŒŒì¼ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
        
        Args:
            input_file (str): ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        try:
            input_path = Path(input_file)
            file_stem = input_path.stem
            
            # 1ë‹¨ê³„: ë…¸ì´ì¦ˆ ì œê±°
            denoised_file = self.audio_out_dir / f"{file_stem}_denoised.wav"
            self.denoise_audio(input_file, str(denoised_file))
            
            # 2ë‹¨ê³„: audio_outputìœ¼ë¡œ ë³µì‚¬ (íŒŒì´í”„ë¼ì¸ êµ¬ì¡° ìœ ì§€)
            output_audio_file = self.audio_output_dir / f"{file_stem}_denoised.wav"
            import shutil
            shutil.copy2(denoised_file, output_audio_file)
            
            # 3ë‹¨ê³„: STT ì²˜ë¦¬
            transcript_file = self.script_output_dir / f"{file_stem}_transcript.txt"
            srt_file = self.script_output_dir / f"{file_stem}_subtitle.srt"
            transcribed_text = self.transcribe_audio(output_audio_file, transcript_file, srt_file)
            
            logger.info(f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {input_file}")
            return transcribed_text
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({input_file}): {e}")
            raise
    
    def process_all_files(self):
        """audio_input í´ë”ì˜ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬"""
        # ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì
        audio_extensions = ['*.wav', '*.mp3', '*.m4a', '*.flac', '*.ogg']
        
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(glob.glob(str(self.audio_input_dir / ext)))
        
        if not audio_files:
            logger.warning(f"audio_input í´ë”ì— ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"ì´ {len(audio_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
        
        results = []
        for i, audio_file in enumerate(audio_files, 1):
            try:
                logger.info(f"[{i}/{len(audio_files)}] ì²˜ë¦¬ ì¤‘: {Path(audio_file).name}")
                result = self.process_single_file(audio_file)
                results.append({
                    'file': Path(audio_file).name,
                    'status': 'success',
                    'text': result
                })
            except Exception as e:
                logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {audio_file} - {e}")
                results.append({
                    'file': Path(audio_file).name,
                    'status': 'failed',
                    'error': str(e)
                })
        
        # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì €ì¥
        self._save_processing_summary(results)
        
        logger.info("ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
        return results
    
    def _save_processing_summary(self, results):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì €ì¥"""
        summary_file = self.script_output_dir / f"processing_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=== ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ===\n")
            f.write(f"ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì´ íŒŒì¼ ìˆ˜: {len(results)}\n")
            
            success_count = sum(1 for r in results if r['status'] == 'success')
            failed_count = len(results) - success_count
            
            f.write(f"ì„±ê³µ: {success_count}ê°œ\n")
            f.write(f"ì‹¤íŒ¨: {failed_count}ê°œ\n")
            f.write("-" * 50 + "\n\n")
            
            for result in results:
                f.write(f"íŒŒì¼: {result['file']}\n")
                f.write(f"ìƒíƒœ: {result['status']}\n")
                if result['status'] == 'success':
                    f.write(f"í…ìŠ¤íŠ¸: {result['text'][:200]}...\n")
                else:
                    f.write(f"ì˜¤ë¥˜: {result['error']}\n")
                f.write("-" * 30 + "\n")
        
        logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì €ì¥: {summary_file}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=== ìŒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
    print("audio_input â†’ ë…¸ì´ì¦ˆì œê±° â†’ audio_out â†’ STT â†’ script_output")
    print()
    
    try:
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        use_gpu = torch.cuda.is_available()
        if use_gpu:
            print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
        else:
            print("âš ï¸  GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        
        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        pipeline = AudioPipeline(use_gpu=use_gpu)
        
        # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
        results = pipeline.process_all_files()
        
        # ê²°ê³¼ ì¶œë ¥
        if results:
            success_count = sum(1 for r in results if r['status'] == 'success')
            print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{len(results)}ê°œ íŒŒì¼ ì„±ê³µ")
        else:
            print("\nâš ï¸  ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("audio_input í´ë”ì— ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
