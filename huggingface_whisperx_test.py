# transcribe_diarize.py
import os, argparse, pathlib
from pathlib import Path
import torch, whisperx
from whisperx.diarize import DiarizationPipeline
import huggingface_hub
import gc
import time
huggingface_hub.login("hf_")

# Windows ì „ìš©: PyTorch DLL ê²½ë¡œ ìš°ì„ 
try:
    os.add_dll_directory(str(pathlib.Path(torch.__file__).parents[1] / "lib"))
except Exception:
    pass

# ì˜µì…˜: ì†ë„ í–¥ìƒ(TF32). í•„ìš” ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬.
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

def mmss(t):
    t = 0.0 if not isinstance(t, (int, float)) or t != t or t < 0 else float(t)
    m = int(t // 60)
    s = int(round(t - m * 60))
    if s == 60:
        m += 1
        s = 0
    return f"{m:02d}:{s:02d}"

def write_lines(p: Path, lines):
    p.parent.mkdir(parents=True, exist_ok=True)
    with p.open("w", encoding="utf-8") as f:
        for ln in lines:
            f.write(ln + "\n")

def build_diar_pipeline(token: str, prefer_device: str):
    try:
        return DiarizationPipeline(use_auth_token=token, device=prefer_device)
    except OSError as e:
        print(f"[WARN] GPU diarization ì‹¤íŒ¨: {e}\n[INFO] CPUë¡œ í´ë°±.")
        return DiarizationPipeline(use_auth_token=token, device="cpu")

def looks_blackwell(gpu_name: str):
    n = gpu_name.lower()
    keys = ["rtx 50", "rtx5", "5070", "5080", "5090", "blackwell", "gb2", "gb20"]
    return any(k in n for k in keys)

def cleanup_memory():
    """ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜"""
    print("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    time.sleep(1)  # ì‹œìŠ¤í…œ ì•ˆì •í™”ë¥¼ ìœ„í•œ ëŒ€ê¸°

def cleanup_models(*models):
    """ëª¨ë¸ ê°ì²´ë“¤ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    for model in models:
        if model is not None:
            del model
    cleanup_memory()

def process_one(fp: Path, out_dir: Path, model, diar_pipe, device: str, batch: int,
                min_spk, max_spk, load_model_fn, compute_type: str):
    align_model = None
    meta = None
    
    try:
        print(f"ğŸµ ì²˜ë¦¬ ì‹œì‘: {fp.name}")
        audio = whisperx.load_audio(str(fp))

        # 1) ASR(+ì–¸ì–´ê°ì§€). INT8 ê²½ë¡œ(cuBLAS) ì‹¤íŒ¨ ì‹œ FP16ìœ¼ë¡œ 1íšŒ ìë™ ì¬ì‹œë„.
        try:
            asr = model.transcribe(audio, batch_size=batch)
        except RuntimeError as e:
            msg = str(e).lower()
            if ("cublas_status_not_supported" in msg or "cublas" in msg) and "int8" in (compute_type or ""):
                print("[INFO] cuBLAS INT8 ë¬¸ì œ ê°ì§€. FP16ìœ¼ë¡œ ì¬ì‹œë„.")
                model = load_model_fn("float16")
                asr = model.transcribe(audio, batch_size=batch)
            else:
                raise

        lang = asr.get("language", "ko")
        print(f"   - ê°ì§€ëœ ì–¸ì–´: {lang}")

        # 2) ì •ë ¬
        align_model, meta = whisperx.load_align_model(language_code=lang, device=device)
        asr_aligned = whisperx.align(
            asr["segments"], align_model, meta, audio, device, return_char_alignments=False
        )

        # 3) í™”ìë¶„ë¦¬
        diar_kwargs = {}
        if min_spk is not None:
            diar_kwargs["min_speakers"] = min_spk
        if max_spk is not None:
            diar_kwargs["max_speakers"] = max_spk
        diar_segments = diar_pipe(audio, **diar_kwargs)
        asr_spk = whisperx.assign_word_speakers(diar_segments, asr_aligned)

        # 4) ì €ì¥: [mm:ss] í™”ìN : í…ìŠ¤íŠ¸
        spk_map, lines = {}, []
        for seg in sorted(asr_spk["segments"], key=lambda x: x.get("start", 0.0)):
            txt = (seg.get("text") or "").strip()
            if not txt:
                continue
            spk = seg.get("speaker", "UNK")
            if spk not in spk_map:
                # A, B, C, ... í˜•ì‹ìœ¼ë¡œ í™”ì ì´ë¦„ ìƒì„±
                speaker_letter = chr(ord('A') + len(spk_map))
                spk_map[spk] = f"í™”ì{speaker_letter}"
            lines.append(f"[{mmss(seg.get('start', 0.0))}] {spk_map[spk]} : {txt}")

        out_path = out_dir / f"{fp.stem}_transcript_{lang}.txt"
        write_lines(out_path, lines)
        
        print(f" ì™„ë£Œ: {fp.name} -> {out_path.name}")
        return out_path
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {fp.name} - {e}")
        raise
    finally:
        # íŒŒì¼ë³„ ì²˜ë¦¬ í›„ ì •ë¦¬
        if align_model is not None:
            cleanup_models(align_model)
            align_model = None
        if meta is not None:
            del meta
            meta = None
        if 'audio' in locals():
            del audio
        cleanup_memory()

def main():
    ap = argparse.ArgumentParser(
        description="WhisperX + diarization ë°°ì¹˜ ì²˜ë¦¬ (ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ í˜•ì‹ ì§€ì›)",
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python whisperx_test.py --src audio_folder                    # í´ë”ì˜ ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
  python whisperx_test.py --src my_audio.wav                    # ë‹¨ì¼ WAV íŒŒì¼ ì²˜ë¦¬
  python whisperx_test.py --src audio_folder --ext "*.mp3"      # MP3 íŒŒì¼ë§Œ ì²˜ë¦¬
  python whisperx_test.py --src audio_folder --ext "*.wav"      # WAV íŒŒì¼ë§Œ ì²˜ë¦¬
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    ap.add_argument("--src", default="video_input", help="ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ë˜ëŠ” í´ë” (mp4, wav, mp3, flac, m4a, aac, ogg ì§€ì›)")
    ap.add_argument("--out_dir", default="input", help="ì¶œë ¥ í´ë”")
    ap.add_argument("--whisper_model", default="large-v3", help="Whisper ëª¨ë¸ëª…")
    ap.add_argument("--batch_size", type=int, default=8)
    ap.add_argument("--min_speakers", type=int, default=None)
    ap.add_argument("--max_speakers", type=int, default=None)
    ap.add_argument("--hf_token", default=None, help="Hugging Face read í† í°")
    ap.add_argument("--force_cpu_diar", action="store_true", help="í™”ìë¶„ë¦¬ë§Œ CPU ê°•ì œ")
    ap.add_argument("--compute_type", default=None, help='CUDA: float16|bfloat16|float32|int8_float16 ë“±')
    ap.add_argument("--ext", default="*.mp4", help="ê²€ìƒ‰ í™•ì¥ì íŒ¨í„´ (ì˜ˆ: *.mp4, *.wav, *.mp3)")
    ap.add_argument("--cleanup_interval", type=int, default=3, help="ëª¨ë¸ ì •ë¦¬ ì£¼ê¸° (íŒŒì¼ ê°œìˆ˜)")
    args = ap.parse_args()

    token = (
        args.hf_token
        or os.getenv("HUGGINGFACE_HUB_TOKEN")
        or os.getenv("HUGGINGFACE_TOKEN")
        or os.getenv("HF_TOKEN")
    )

    # GPU cuDNN ë¬¸ì œ ìš°íšŒë¥¼ ìœ„í•´ CPU ì‚¬ìš©
    device = "cpu"  # "cuda" if torch.cuda.is_available() else "cpu"
    gpu_name = torch.cuda.get_device_name(0) if device == "cuda" else ""
    is_blackwell = device == "cuda" and looks_blackwell(gpu_name)

    # ê¸°ë³¸ ì •ë°€ë„ ì„ íƒ: Blackwell(RTX 50xx)ì—ì„œëŠ” INT8 ê³„ì—´ íšŒí”¼
    if args.compute_type:
        compute_type = args.compute_type
    else:
        if device == "cuda":
            compute_type = "float16" if is_blackwell else "int8_float16"
        else:
            compute_type = "int8"

    def load_model_with(ct):
        return whisperx.load_model(args.whisper_model, device=device, compute_type=ct)

    # ëª¨ë¸ ë¡œë“œ
    model = load_model_with(compute_type)

    diar_device = "cpu" if args.force_cpu_diar else device
    diar_pipe = build_diar_pipeline(token, diar_device)

    # ì…ë ¥ ìˆ˜ì§‘
    src_path = Path(args.src)
    
    if src_path.is_file():
        files = [src_path]
    else:
        # ì—¬ëŸ¬ ì˜¤ë””ì˜¤ í˜•ì‹ ì§€ì›
        audio_extensions = ["*.mp4", "*.wav", "*.mp3", "*.flac", "*.m4a", "*.aac", "*.ogg"]
        files = []
        
        if args.ext != "*.mp4":  # ì‚¬ìš©ìê°€ íŠ¹ì • í™•ì¥ìë¥¼ ì§€ì •í•œ ê²½ìš°
            files = sorted(src_path.glob(args.ext))
        else:  # ê¸°ë³¸ê°’ì¸ ê²½ìš° ëª¨ë“  ì˜¤ë””ì˜¤ í˜•ì‹ ê²€ìƒ‰
            for ext in audio_extensions:
                files.extend(src_path.glob(ext))
            files = sorted(set(files))  # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    
    assert files, f"{src_path}ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì§€ ëª»í•¨. ì§€ì› í˜•ì‹: {', '.join(audio_extensions)}"
    
    # ì°¾ì€ íŒŒì¼ë“¤ í‘œì‹œ
    print(f"\nğŸ“ ì²˜ë¦¬í•  íŒŒì¼ {len(files)}ê°œ:")
    for i, fp in enumerate(files, 1):
        print(f"  {i}. {fp.name} ({fp.suffix.upper()})")
    print()

    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(files)}ê°œ íŒŒì¼")
    successful = 0
    failed = 0

    for i, fp in enumerate(files, 1):
        try:
            print(f"\n{'='*50}")
            print(f"ğŸ“Š ì§„í–‰ë¥ : {i}/{len(files)} ({i/len(files)*100:.1f}%)")
            
            outp = process_one(
                fp, out_dir, model, diar_pipe, device, args.batch_size,
                args.min_speakers, args.max_speakers, load_model_with, compute_type
            )
            successful += 1
            print(f"OK: {fp.name} -> {outp.name}")
            
        except Exception as e:
            failed += 1
            print(f"ERR: {fp.name}: {e}")
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ì „ì²´ ëª¨ë¸ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
        if i % args.cleanup_interval == 0 and i < len(files):
            print(f"\nğŸ”„ ì£¼ê¸°ì  ëª¨ë¸ ì •ë¦¬ ({i}/{len(files)})")
            cleanup_models(model, diar_pipe)
            
            # ëª¨ë¸ ì¬ë¡œë“œ
            print("ğŸ“¥ ëª¨ë¸ ì¬ë¡œë“œ ì¤‘...")
            model = load_model_with(compute_type)
            diar_pipe = build_diar_pipeline(token, diar_device)
            
            time.sleep(2)  # ì‹œìŠ¤í…œ ì•ˆì •í™”
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*50}")
    print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   - ì„±ê³µ: {successful}ê°œ")
    print(f"   - ì‹¤íŒ¨: {failed}ê°œ")
    print(f"   - ì´ ì²˜ë¦¬: {len(files)}ê°œ")
    
    # ìµœì¢… ì •ë¦¬
    print("\nğŸ§¹ ìµœì¢… ì •ë¦¬...")
    cleanup_models(model, diar_pipe)

if __name__ == "__main__":
    main()



# # ê¸°ë³¸ ì‚¬ìš© (3íŒŒì¼ë§ˆë‹¤ ì •ë¦¬)
# python whisperx_test.py --src video_folder

# # ì •ë¦¬ ì£¼ê¸° ë³€ê²½ (5íŒŒì¼ë§ˆë‹¤)
# python whisperx_test.py --src video_folder --cleanup_interval 5

# # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
# python whisperx_test.py --src video.mp4